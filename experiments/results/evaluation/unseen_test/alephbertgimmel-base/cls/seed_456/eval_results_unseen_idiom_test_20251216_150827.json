{
  "model_checkpoint": "experiments/results/full_fine-tuning/alephbertgimmel-base/cls/seed_456",
  "dataset": "data/splits/unseen_idiom_test.csv",
  "task": "cls",
  "num_samples": 480,
  "metrics": {
    "loss": 0.27248886227607727,
    "model_preparation_time": 0.0051,
    "accuracy": 0.9166666666666666,
    "f1": 0.9165739710789766,
    "precision": 0.9185267857142857,
    "recall": 0.9166666666666666,
    "confusion_matrix_tn": 212.0,
    "confusion_matrix_fp": 28.0,
    "confusion_matrix_fn": 12.0,
    "confusion_matrix_tp": 228.0,
    "runtime": 0.7591,
    "samples_per_second": 632.32,
    "steps_per_second": 39.52
  },
  "eval_config": {
    "batch_size": 16,
    "max_length": 128,
    "device": "cuda"
  },
  "training_config": {
    "learning_rate": 5e-05,
    "batch_size": 32,
    "num_epochs": 8,
    "warmup_ratio": 0.1,
    "weight_decay": 0.01,
    "seed": 456,
    "max_length": 128,
    "label_smoothing": 0.1,
    "lr_scheduler_type": "cosine",
    "gradient_accumulation_steps": 2,
    "fp16": true,
    "bf16": false,
    "use_crf": null
  }
}